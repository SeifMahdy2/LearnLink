{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./Grad_responses.xlsx', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "current_rows = df.shape[0]\n",
    "target_rows = 2000\n",
    "rows_to_add = target_rows - current_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "synthetic_data = df.sample(n=rows_to_add, replace=True).reset_index(drop=True)\n",
    "\n",
    "variation_columns = [\n",
    "    \"How do you prefer to learn new information? (select all that apply)\",\n",
    "    \"How often do you benefit from visual aids (e.g., diagrams, animations)?\",\n",
    "    \"Which of the following tools helps you understand topics better?\",\n",
    "    \"Do you prefer learning at your own pace or following a structured schedule?\",\n",
    "    \"What challenges do you face in traditional classroom learning? (Select all that apply)\",\n",
    "    \"Do you feel that traditional learning methods address your individual needs?\",\n",
    "    \"How important is feedback to you while learning new material?\",\n",
    "    \"Do you think that gamified elements (e.g., points, levels, badges) make learning more enjoyable?\",\n",
    "    \"What motivates you to stay engaged with learning?\",\n",
    "    \"How comfortable are you using technology (e.g., apps, online platforms) for learning?\",\n",
    "    \"Do you trust AI-based systems to provide personalized learning recommendations?\",\n",
    "    \"Would you like explanations for why a system recommends certain lessons or feedback?\",\n",
    "    \"How likely are you to use an AI tutoring system if it provides personalized content, feedback, and gamified quizzes?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete. The dataset is saved as 'Augmented_Grad_responses.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "for col in variation_columns:\n",
    "    unique_values = df[col].dropna().unique()\n",
    "    synthetic_data[col] = np.random.choice(unique_values, size=rows_to_add)\n",
    "\n",
    "start_date = pd.to_datetime(\"2025-01-01\")\n",
    "end_date = pd.to_datetime(\"2025-02-01\")\n",
    "synthetic_data[\"Timestamp\"] = pd.to_datetime(\n",
    "    np.random.uniform(start_date.timestamp(), end_date.timestamp(), size=rows_to_add), unit='s'\n",
    ")\n",
    "\n",
    "augmented_df = pd.concat([df, synthetic_data], ignore_index=True)\n",
    "\n",
    "augmented_df.to_excel(\"Augmented_Grad_responses.xlsx\", index=False)\n",
    "\n",
    "print(\"Augmentation complete. The dataset is saved as 'Augmented_Grad_responses.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Augmented_Grad_responses.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "if \"Timestamp\" in df.columns:\n",
    "    df = df.drop(columns=[\"Timestamp\"])\n",
    "\n",
    "likert_mapping = {\n",
    "    \"Always\": 3, \"Often\": 2, \"Sometimes\": 1, \"Rarely\": 0, \"Never\": 0\n",
    "}\n",
    "df[\"How often do you benefit from visual aids (e.g., diagrams, animations)?\"] = df[\"How often do you benefit from visual aids (e.g., diagrams, animations)?\"].map(likert_mapping)\n",
    "\n",
    "binary_mapping = {\"Yes\": 1, \"No\": 0, \"Somewhat\": 0.5}\n",
    "for col in [\n",
    "    \"Do you trust AI-based systems to provide personalized learning recommendations?\",\n",
    "    \"Do you think that gamified elements (e.g., points, levels, badges) make learning more enjoyable?\",\n",
    "    \"Would you like explanations for why a system recommends certain lessons or feedback?\",\n",
    "    \"Have you used educational tools or platforms with gamified elements before?\"\n",
    "]:\n",
    "    df[col] = df[col].map(binary_mapping)\n",
    "\n",
    "feedback_mapping = {\"Very important\": 3, \"Important\": 2, \"Somewhat important\": 1, \"Not important\": 0}\n",
    "df[\"How important is feedback to you while learning new material?\"] = df[\"How important is feedback to you while learning new material?\"].map(feedback_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed successfully! The dataset is saved as 'Processed_Grad_responses.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Augmented_Grad_responses.xlsx\"  \n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "def contains_preference(row, keyword):\n",
    "    return 1 if keyword in str(row) else 0\n",
    "\n",
    "learning_pref_col = \"How do you prefer to learn new information? (select all that apply)\"\n",
    "\n",
    "if learning_pref_col not in df.columns:\n",
    "    raise ValueError(f\"Missing column: {learning_pref_col}. Ensure augmentation is correct.\")\n",
    "\n",
    "df[\"Visual_Learner\"] = df[learning_pref_col].apply(lambda x: contains_preference(x, \"Watching videos or animations\"))\n",
    "df[\"Auditory_Learner\"] = df[learning_pref_col].apply(lambda x: contains_preference(x, \"Listening to explanations\"))\n",
    "df[\"Kinesthetic_Learner\"] = df[learning_pref_col].apply(lambda x: contains_preference(x, \"Hands-on practice\"))\n",
    "\n",
    "df = df.drop(columns=[learning_pref_col])\n",
    "\n",
    "df.to_excel(\"Processed_Grad_responses.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Processed_Grad_responses.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded Successfully!\n",
      "Feature Shape: (2000, 121), Label Shape: (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "df = df.select_dtypes(exclude=[\"datetime64\"])\n",
    "\n",
    "df.fillna(df.mode().iloc[0], inplace=True)\n",
    "\n",
    "learning_style_columns = [\"Visual_Learner\", \"Auditory_Learner\", \"Kinesthetic_Learner\"]\n",
    "X = pd.get_dummies(df.drop(columns=learning_style_columns))  \n",
    "Y = df[learning_style_columns]\n",
    "\n",
    "# Print dataset shape\n",
    "print(\"Dataset Loaded Successfully!\")\n",
    "print(f\"Feature Shape: {X.shape}, Label Shape: {Y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split Completed!\n",
      "Training Set Size: 1600 samples\n",
      "Testing Set Size: 400 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into 80% training and 20% testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data Split Completed!\")\n",
    "print(f\"Training Set Size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing Set Size: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'metric': 'euclidean', 'n_neighbors': 25, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [5, 10, 15, 20, 25, 30],  \n",
    "    \"weights\": [\"uniform\", \"distance\"],  \n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"]  \n",
    "}\n",
    "\n",
    "# Initialize KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized KNN Model Trained Successfully!\n"
     ]
    }
   ],
   "source": [
    "best_knn = KNeighborsClassifier(\n",
    "    n_neighbors=best_params[\"n_neighbors\"],\n",
    "    weights=best_params[\"weights\"],\n",
    "    metric=best_params[\"metric\"]\n",
    ")\n",
    "best_knn.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_final = best_knn.predict(X_test)\n",
    "\n",
    "print(\"Optimized KNN Model Trained Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Model Evaluation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.65      0.59       222\n",
      "           1       0.54      0.55      0.54       225\n",
      "           2       0.54      0.69      0.60       211\n",
      "\n",
      "   micro avg       0.54      0.63      0.58       658\n",
      "   macro avg       0.54      0.63      0.58       658\n",
      "weighted avg       0.54      0.63      0.58       658\n",
      " samples avg       0.53      0.60      0.52       658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\Main_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\anaconda3\\envs\\Main_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\anaconda3\\envs\\Main_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Optimized Model Evaluation:\\n\", classification_report(Y_test, Y_pred_final.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized model saved successfully as: optimized_knn_learning_style_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the optimized model\n",
    "joblib.dump(best_knn, \"knn_learning_style_model.pkl\")\n",
    "print(\"Optimized model saved successfully as: optimized_knn_learning_style_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
